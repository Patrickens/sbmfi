{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f2eda9d-9757-47d7-86df-93fab56b6b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "from sbmfi.models.small_models import spiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35af9c52-837b-485f-b72c-670bb13c047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def cartesian_to_polar_nd(coords):\n",
    "    \"\"\"\n",
    "    Transforms Cartesian coordinates of a point in n-dimensional space to polar coordinates.\n",
    "\n",
    "    Parameters:\n",
    "        coords (list or tuple): Cartesian coordinates [x1, x2, ..., xn].\n",
    "\n",
    "    Returns:\n",
    "        tuple: Polar coordinates (r, theta1, theta2, ..., theta_{n-1}).\n",
    "    \"\"\"\n",
    "    n = len(coords)\n",
    "    r = math.sqrt(sum(c**2 for c in coords))\n",
    "    if r == 0:\n",
    "        return (0,) + (0,) * (n - 1)  # Special case: origin\n",
    "    \n",
    "    angles = []\n",
    "    for i in range(n - 1):\n",
    "        norm = math.sqrt(sum(c**2 for c in coords[i:]))\n",
    "        angle = math.acos(coords[i] / norm) if norm != 0 else 0\n",
    "        angles.append(angle)\n",
    "    \n",
    "    if coords[-1] < 0:  # Adjust the last angle to the full circle range\n",
    "        angles[-1] = 2 * math.pi - angles[-1]\n",
    "\n",
    "    return (r, *angles)\n",
    "\n",
    "\n",
    "def polar_to_cartesian_nd(r, *angles):\n",
    "    \"\"\"\n",
    "    Transforms polar coordinates of a point in n-dimensional space back to Cartesian coordinates.\n",
    "\n",
    "    Parameters:\n",
    "        r (float): Radius (distance from origin).\n",
    "        angles (float): Angles (theta1, theta2, ..., theta_{n-1}).\n",
    "\n",
    "    Returns:\n",
    "        list: Cartesian coordinates [x1, x2, ..., xn].\n",
    "    \"\"\"\n",
    "    n = len(angles) + 1\n",
    "    coords = []\n",
    "    for i in range(n):\n",
    "        if i < n - 1:\n",
    "            product = r\n",
    "            for j in range(i):\n",
    "                product *= math.sin(angles[j])\n",
    "            product *= math.cos(angles[i])\n",
    "        else:\n",
    "            product = r\n",
    "            for j in range(n - 1):\n",
    "                product *= math.sin(angles[j])\n",
    "        coords.append(product)\n",
    "    return coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "300ed80f-4bcc-49ee-a204-04b6ab9a9798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polar: (1.7320508075688772, 0.9553166181245092, 0.7853981633974484)\n",
      "Cartesian: [1.0, 0.9999999999999998, 1.0]\n"
     ]
    }
   ],
   "source": [
    "cartesian_coords = (1, 1, 1)\n",
    "polar_coords = cartesian_to_polar_nd(cartesian_coords)\n",
    "print(\"Polar:\", polar_coords)\n",
    "\n",
    "back_to_cartesian = polar_to_cartesian_nd(*polar_coords)\n",
    "print(\"Cartesian:\", back_to_cartesian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b1eddf6-8514-4d84-9df3-2eed3573f92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polar: (2.0, 1.0471975511965979, 0.9553166181245092, 0.7853981633974484)\n",
      "Cartesian: [0.9999999999999998, 1.0000000000000002, 1.0, 1.0000000000000002]\n"
     ]
    }
   ],
   "source": [
    "cartesian_coords = (1, 1, 1, 1)\n",
    "polar_coords = cartesian_to_polar_nd(cartesian_coords)\n",
    "print(\"Polar:\", polar_coords)\n",
    "\n",
    "back_to_cartesian = polar_to_cartesian_nd(*polar_coords)\n",
    "print(\"Cartesian:\", back_to_cartesian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3931c3-94fe-4608-8916-2e43d509ff07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f11dcf-57c8-495d-99c8-c724f0589df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-07-27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python_projects\\sbmfi\\venv\\lib\\site-packages\\torch\\__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\tensor\\python_tensor.cpp:434.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types (dtype('int64'), dtype('<U3')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mC:\\python_projects\\sbmfi\\venv\\lib\\site-packages\\pandas\\core\\indexes\\range.py:1128\u001b[0m, in \u001b[0;36mRangeIndex._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1128\u001b[0m     rstart \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1129\u001b[0m     rstop \u001b[38;5;241m=\u001b[39m op(left\u001b[38;5;241m.\u001b[39mstop, right)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mspiro\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtorch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuild_simulator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python_projects\\sbmfi\\src\\sbmfi\\models\\small_models.py:200\u001b[0m, in \u001b[0;36mspiro\u001b[1;34m(backend, auto_diff, batch_size, add_biomass, v2_reversible, ratios, build_simulator, add_cofactors, which_measurements, seed, which_labellings, include_bom, v5_reversible, measured_boundary_fluxes, n_obs, kernel_id, L_12_omega, clip_min, transformation)\u001b[0m\n\u001b[0;32m    197\u001b[0m     measured_boundary_fluxes\u001b[38;5;241m.\u001b[39mappend(biomass_id)\n\u001b[0;32m    198\u001b[0m     measured_boundary_fluxes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(measured_boundary_fluxes)\n\u001b[1;32m--> 200\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msimulator_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_or_file_or_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspiro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_diff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_diff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetabolite_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetabolite_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreaction_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreaction_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_labelling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubstrate_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mratio_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mratio_repo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeasurements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotation_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmet_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_simulator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_simulator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfree_reaction_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeasured_boundary_fluxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_biomass:\n\u001b[0;32m    218\u001b[0m     bm \u001b[38;5;241m=\u001b[39m Reaction(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbm\u001b[39m\u001b[38;5;124m'\u001b[39m, lower_bound\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, upper_bound\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m)\n",
      "File \u001b[1;32mc:\\python_projects\\sbmfi\\src\\sbmfi\\models\\build_models.py:2261\u001b[0m, in \u001b[0;36msimulator_factory\u001b[1;34m(id_or_file_or_model, name, backend, solver, batch_size, auto_diff, fkwargs, reaction_list, reaction_kwargs, metabolite_kwargs, input_labelling, ratio_repo, measurements, build_simulator, device, ratios, seed, free_reaction_id, kernel_id)\u001b[0m\n\u001b[0;32m   2254\u001b[0m model\u001b[38;5;241m.\u001b[39madd_reactions(\n\u001b[0;32m   2255\u001b[0m     reaction_list\u001b[38;5;241m=\u001b[39mreaction_list,\n\u001b[0;32m   2256\u001b[0m     reaction_kwargs\u001b[38;5;241m=\u001b[39mreaction_kwargs,\n\u001b[0;32m   2257\u001b[0m     metabolite_kwargs\u001b[38;5;241m=\u001b[39mmetabolite_kwargs\n\u001b[0;32m   2258\u001b[0m )\n\u001b[0;32m   2260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (ratio_repo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m ratios:\n\u001b[1;32m-> 2261\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_ratio_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratio_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mratio_repo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_labelling \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2264\u001b[0m     model\u001b[38;5;241m.\u001b[39mset_input_labelling(input_labelling\u001b[38;5;241m=\u001b[39minput_labelling)\n",
      "File \u001b[1;32mc:\\python_projects\\sbmfi\\src\\sbmfi\\core\\model.py:825\u001b[0m, in \u001b[0;36mRatioMixin.set_ratio_repo\u001b[1;34m(self, ratio_repo)\u001b[0m\n\u001b[0;32m    822\u001b[0m reaction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreactions\u001b[38;5;241m.\u001b[39mget_by_id(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mreac_id)\n\u001b[0;32m    823\u001b[0m always_rev \u001b[38;5;241m=\u001b[39m (reaction\u001b[38;5;241m.\u001b[39mupper_bound \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (reaction\u001b[38;5;241m.\u001b[39mrho_max \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m--> 825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (reac_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabelling_reactions\u001b[49m) \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[0;32m    826\u001b[0m         (always_rev \u001b[38;5;129;01mand\u001b[39;00m (reaction\u001b[38;5;241m.\u001b[39m_rev_reaction\u001b[38;5;241m.\u001b[39mid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabelling_reactions)):\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirst add reactions and atom_mappings; \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreac_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in labelling_reactions\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reac_id \u001b[38;5;129;01min\u001b[39;00m num:\n",
      "File \u001b[1;32mc:\\python_projects\\sbmfi\\src\\sbmfi\\core\\model.py:232\u001b[0m, in \u001b[0;36mLabellingModel.labelling_reactions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_labelling_reactions\u001b[38;5;241m.\u001b[39mappend(reaction\u001b[38;5;241m.\u001b[39m_rev_reaction)\n\u001b[0;32m    229\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_only_rev[reaction\u001b[38;5;241m.\u001b[39m_rev_reaction\u001b[38;5;241m.\u001b[39mid] \u001b[38;5;241m=\u001b[39m reaction\u001b[38;5;241m.\u001b[39mid\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jacobian \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_la\u001b[38;5;241m.\u001b[39mget_tensor(\n\u001b[1;32m--> 232\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_la\u001b[38;5;241m.\u001b[39m_batch_size, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_labelling_reactions), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_id\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    233\u001b[0m )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_labelling_reactions\n",
      "File \u001b[1;32mc:\\python_projects\\sbmfi\\src\\sbmfi\\core\\model.py:177\u001b[0m, in \u001b[0;36mLabellingModel.state_id\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstate_id\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mIndex:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# this assumes that we return MDVs; therefore cumomers reimplement this\u001b[39;00m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mIndex([\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tup)\n\u001b[1;32m--> 177\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m met \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasurements\u001b[49m\n\u001b[0;32m    178\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m tup \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(repeat(met\u001b[38;5;241m.\u001b[39mid), \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mrange\u001b[39m(met\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m    179\u001b[0m     ], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmdv_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\python_projects\\sbmfi\\src\\sbmfi\\core\\model.py:209\u001b[0m, in \u001b[0;36mLabellingModel.measurements\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeasurements\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_measurements:\n\u001b[1;32m--> 209\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_measurements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetabolites_in_state\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpseudo_metabolites  \u001b[38;5;66;03m# basically errthangg\u001b[39;00m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_measurements\n",
      "File \u001b[1;32mc:\\python_projects\\sbmfi\\src\\sbmfi\\core\\model.py:637\u001b[0m, in \u001b[0;36mLabellingModel.metabolites_in_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmetabolites_in_state\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    636\u001b[0m     metabolites_in_state \u001b[38;5;241m=\u001b[39m DictList()\n\u001b[1;32m--> 637\u001b[0m     polytope \u001b[38;5;241m=\u001b[39m \u001b[43mextract_labelling_polytope\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoordinates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthermo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    639\u001b[0m     unbalanced \u001b[38;5;241m=\u001b[39m (polytope\u001b[38;5;241m.\u001b[39mS \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m)\u001b[38;5;241m.\u001b[39mall(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m|\u001b[39m (polytope\u001b[38;5;241m.\u001b[39mS \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m)\u001b[38;5;241m.\u001b[39mall(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (unbalanced)\u001b[38;5;241m.\u001b[39many():\n",
      "File \u001b[1;32mc:\\python_projects\\sbmfi\\src\\sbmfi\\core\\polytopia.py:489\u001b[0m, in \u001b[0;36mextract_labelling_polytope\u001b[1;34m(model, coordinates, zero_tol, inf_bound)\u001b[0m\n\u001b[0;32m    487\u001b[0m Avar\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m Avar\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|ub\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    488\u001b[0m A_1 \u001b[38;5;241m=\u001b[39m A \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 489\u001b[0m A_1\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m \u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m|lb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m    490\u001b[0m A\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|ub\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    491\u001b[0m A \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([Avar, Avar_1, A, A_1], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\python_projects\\sbmfi\\venv\\lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\python_projects\\sbmfi\\venv\\lib\\site-packages\\pandas\\core\\arraylike.py:186\u001b[0m, in \u001b[0;36mOpsMixin.__add__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__add__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m    100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m    Get Addition of DataFrame and other, column-wise.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    moose     3.0     NaN\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\python_projects\\sbmfi\\venv\\lib\\site-packages\\pandas\\core\\indexes\\range.py:1144\u001b[0m, in \u001b[0;36mRangeIndex._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mZeroDivisionError\u001b[39;00m):\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;66;03m# test_arithmetic_explicit_conversions\u001b[39;00m\n\u001b[1;32m-> 1144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\python_projects\\sbmfi\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:7238\u001b[0m, in \u001b[0;36mIndex._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   7228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   7229\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(other, Index)\n\u001b[0;32m   7230\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_object_dtype(other\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   7234\u001b[0m     \u001b[38;5;66;03m# a chance to implement ops before we unwrap them.\u001b[39;00m\n\u001b[0;32m   7235\u001b[0m     \u001b[38;5;66;03m# See https://github.com/pandas-dev/pandas/issues/31109\u001b[39;00m\n\u001b[0;32m   7236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m-> 7238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\python_projects\\sbmfi\\venv\\lib\\site-packages\\pandas\\core\\base.py:1382\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1379\u001b[0m     rvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(rvalues\u001b[38;5;241m.\u001b[39mstart, rvalues\u001b[38;5;241m.\u001b[39mstop, rvalues\u001b[38;5;241m.\u001b[39mstep)\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1382\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mC:\\python_projects\\sbmfi\\venv\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:283\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    279\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 283\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mC:\\python_projects\\sbmfi\\venv\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:218\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    215\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 218\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    221\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[0;32m    222\u001b[0m     ):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('int64'), dtype('<U3')) -> None"
     ]
    }
   ],
   "source": [
    "model, kwargs = spiro(backend='torch', build_simulator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2f3797a-460d-4020-bb2b-50e1014d43df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.Size((1,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1820186-86a2-4996-98d0-7f3c814ac810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.079020067859467\n",
      "Proposed move from x=[0. 0.] to y=[1.72783617 2.20455628]\n",
      "Computed Peskun-optimal acceptance probability = 0.0169\n",
      "0.06580838778721143 [1.72783617 2.20455628]\n",
      "Next state of the chain = [0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def multiple_try_metropolis_step(\n",
    "    x,\n",
    "    log_pi,          # function: log of target density, log_pi(state)\n",
    "    sample_q,        # function: sample_q(current_state) -> propose new state\n",
    "    log_q,           # function: log_q(from_state, to_state) -> log of proposal density\n",
    "    K=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs one Multiple-Try Metropolis step from current state x.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        Current state of the chain.\n",
    "    log_pi : callable\n",
    "        log_pi(z) returns log of the target density at z (up to an additive constant).\n",
    "    sample_q : callable\n",
    "        sample_q(z) returns a single random draw from the proposal distribution q(z -> .).\n",
    "    log_q : callable\n",
    "        log_q(z_from, z_to) returns the log of the proposal density q(z_from -> z_to).\n",
    "    K : int\n",
    "        Number of multiple tries in each direction.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_new : np.ndarray\n",
    "        The next state of the chain after this MTM step.\n",
    "    \"\"\"\n",
    "    # 1) Propose K candidates from x\n",
    "    Y = [sample_q(x) for _ in range(K)]  # y_1, ..., y_K\n",
    "\n",
    "    # 2) Compute forward weights w_i = π(y_i)*q(y_i->x)\n",
    "    #    (We actually work in log-domain to avoid underflow)\n",
    "    log_w = []\n",
    "    for y in Y:\n",
    "        log_wi = log_pi(y) + log_q(y, x)\n",
    "        log_w.append(log_wi)\n",
    "    # Convert log-weights to normal scale\n",
    "    w = np.exp(log_w - np.max(log_w))  # subtract max for numerical stability\n",
    "    W = np.sum(w)\n",
    "\n",
    "    # 3) Choose one candidate y_i with probability proportional to w_i\n",
    "    i = np.random.choice(K, p=w / W)\n",
    "    y_chosen = Y[i]\n",
    "\n",
    "    # 4) From y_i, propose K new points (including x as first one)\n",
    "    Z = [x] + [sample_q(y_chosen) for _ in range(K - 1)]  # z_1 = x, plus K-1 others\n",
    "\n",
    "    # 5) Compute reverse weights w'_j = π(z_j)*q(z_j->y_i)\n",
    "    log_wprime = []\n",
    "    for z_j in Z:\n",
    "        log_wpj = log_pi(z_j) + log_q(z_j, y_chosen)\n",
    "        log_wprime.append(log_wpj)\n",
    "    wprime = np.exp(log_wprime - np.max(log_wprime))\n",
    "    Wprime = np.sum(wprime)\n",
    "\n",
    "    # 6) Probability that we \"select x out of Z\" in the reverse proposals\n",
    "    #    (the analog of \"accepting\" in traditional MH)\n",
    "    #    We do a discrete draw among Z with p'_j ~ w'_j / sum(w'_j)\n",
    "    j = np.random.choice(K, p=wprime / Wprime)\n",
    "\n",
    "    # 7) If j = 0 => we re-selected x (the first in Z). Accept the move to y_i.\n",
    "    #    Otherwise, reject (remain at x).\n",
    "    if j == 0:\n",
    "        x_new = y_chosen\n",
    "    else:\n",
    "        x_new = x\n",
    "\n",
    "    return x_new\n",
    "\n",
    "\n",
    "def peskun_optimal_acceptance_ratio(\n",
    "    x,\n",
    "    y,\n",
    "    Y,      # The K proposals from x: [y_1, ..., y_K]\n",
    "    Z,      # The K proposals from y (including x): [z_1, ..., z_K], with z_1 = x\n",
    "    log_pi,\n",
    "    log_q\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the Peskun-optimal acceptance probability alpha(x->y)\n",
    "    for a multiple-try Metropolis proposal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        Current state.\n",
    "    y : np.ndarray\n",
    "        Chosen proposal from x.\n",
    "    Y : list of np.ndarray\n",
    "        The K proposals from x, including y (or at least a set containing y).\n",
    "    Z : list of np.ndarray\n",
    "        The K proposals from y, with Z[0] = x and others random.\n",
    "    log_pi : callable\n",
    "        log_pi(z) = log of target density at z.\n",
    "    log_q : callable\n",
    "        log_q(z_from, z_to) = log of proposal density q(z_from->z_to).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    alpha_xy : float\n",
    "        The acceptance probability alpha(x->y).\n",
    "    \"\"\"\n",
    "    # Weights for forward direction: w_i = pi(y_i)* q(y_i-> x)\n",
    "    log_w_forward = np.array([log_pi(yi) + log_q(yi, x) for yi in Y])\n",
    "    # Weights for reverse direction: w'_j = pi(z_j)* q(z_j-> y)\n",
    "    log_w_reverse = np.array([log_pi(zj) + log_q(zj, y) for zj in Z])\n",
    "\n",
    "    # Convert to numerical scale safely\n",
    "    max_fw = np.max(log_w_forward)\n",
    "    max_rv = np.max(log_w_reverse)\n",
    "\n",
    "    w_forward = np.exp(log_w_forward - max_fw)\n",
    "    w_reverse = np.exp(log_w_reverse - max_rv)\n",
    "\n",
    "    W_forward = np.sum(w_forward)\n",
    "    W_reverse = np.sum(w_reverse)\n",
    "\n",
    "    # Identify log_pi(x), log_pi(y), log_q(x->y), log_q(y->x)\n",
    "    lx = log_pi(x)\n",
    "    ly = log_pi(y)\n",
    "    lqxy = log_q(x, y)\n",
    "    lqyx = log_q(y, x)\n",
    "\n",
    "    # Peskun-optimal acceptance ratio:\n",
    "    #     alpha = min(\n",
    "    #         1,\n",
    "    #         [ π(y)* q(y->x) * W_forward ] / [ π(x)* q(x->y) * W_reverse ]\n",
    "    #     )\n",
    "    # We'll compute that in log form to avoid underflow:\n",
    "    log_num = ly + lqyx + np.log(W_forward)\n",
    "    log_den = lx + lqxy + np.log(W_reverse)\n",
    "    log_ratio = log_num - log_den\n",
    "    print(log_ratio)\n",
    "    alpha = min(1.0, np.exp(log_ratio))\n",
    "    return alpha\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Example log of target density: standard 2D Gaussian\n",
    "    def log_pi_gaussian(z):\n",
    "        return -0.5 * np.sum(z**2)  # ignoring constant terms for simplicity\n",
    "\n",
    "    # Example proposal: isotropic Gaussian with variance = 1\n",
    "    def sample_q(z):\n",
    "        return z + np.random.randn(*z.shape)\n",
    "\n",
    "    # Log of that proposal density q(x->y): Gaussian around x with identity cov\n",
    "    def log_q(z_from, z_to):\n",
    "        diff = z_to - z_from\n",
    "        # log of N(0, I) = -0.5 * diff^2 - (D/2)*log(2π)\n",
    "        # ignoring constant - (dim/2)*log(2π) for M-H ratio (cancels out anyway)\n",
    "        return -0.5 * np.sum(diff**2)\n",
    "\n",
    "    np.random.seed(8)\n",
    "\n",
    "    # Current state\n",
    "    x_current = np.array([0.0, 0.0])\n",
    "\n",
    "    # Number of multiple tries\n",
    "    K = 4\n",
    "\n",
    "    # 1) Generate K proposals from x\n",
    "    Y = [sample_q(x_current) for _ in range(K)]\n",
    "\n",
    "    # 2) Suppose we pick the last one, y_chosen = Y[-1] (for demonstration)\n",
    "    y_chosen = Y[-1]\n",
    "\n",
    "    # 3) Generate K proposals from y_chosen, with x included as the first\n",
    "    Z = [x_current] + [sample_q(y_chosen) for _ in range(K - 1)]\n",
    "\n",
    "    # 4) Compute acceptance probability alpha(x->y_chosen)\n",
    "    alpha_val = peskun_optimal_acceptance_ratio(\n",
    "        x_current,\n",
    "        y_chosen,\n",
    "        Y,\n",
    "        Z,\n",
    "        log_pi_gaussian,\n",
    "        log_q\n",
    "    )\n",
    "\n",
    "    print(f\"Proposed move from x={x_current} to y={y_chosen}\")\n",
    "    print(f\"Computed Peskun-optimal acceptance probability = {alpha_val:.4f}\")\n",
    "\n",
    "    # 5) You can accept/reject with this probability:\n",
    "    a = np.random.rand()\n",
    "    print(a, y_chosen)\n",
    "    if a < alpha_val:\n",
    "        x_new = y_chosen\n",
    "    else:\n",
    "        x_new = x_current\n",
    "\n",
    "    print(f\"Next state of the chain = {x_new}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2012fbf4-9e59-4b11-b86f-c1b69c04512f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.49671415, -0.1382643 ]),\n",
       " array([0.64768854, 1.52302986]),\n",
       " array([-0.23415337, -0.23413696]),\n",
       " array([1.57921282, 0.76743473])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b34e6-fb11-49e9-8074-abe7da67a9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d73693c7-fe1e-4115-a608-3fd40b779198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cartesian_to_polar_nd(coords):\n",
    "    \"\"\"\n",
    "    Converts Cartesian coordinates to polar coordinates (angles only) in n-dimensional space.\n",
    "\n",
    "    Parameters:\n",
    "        coords (array-like): Cartesian coordinates [x1, x2, ..., xn].\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Polar angles (theta1, theta2, ..., theta_{n-1}).\n",
    "    \"\"\"\n",
    "    coords = np.asarray(coords)\n",
    "    n = len(coords)\n",
    "    \n",
    "    # Calculate polar angles\n",
    "    angles = []\n",
    "    for i in range(n - 1):\n",
    "        norm = np.linalg.norm(coords[i:])\n",
    "        if norm == 0:\n",
    "            angle = 0\n",
    "        else:\n",
    "            angle = np.arccos(coords[i] / norm)\n",
    "        angles.append(angle)\n",
    "    return np.array(angles)\n",
    "\n",
    "\n",
    "def polar_to_cartesian_nd(angles):\n",
    "    \"\"\"\n",
    "    Converts polar coordinates (angles only) back to Cartesian coordinates in n-dimensional space.\n",
    "\n",
    "    Parameters:\n",
    "        angles (array-like): Polar angles (theta1, theta2, ..., theta_{n-1}).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Cartesian coordinates [x1, x2, ..., xn].\n",
    "    \"\"\"\n",
    "    angles = np.asarray(angles)\n",
    "    n = len(angles) + 1\n",
    "    \n",
    "    coords = np.zeros(n)\n",
    "    product = 1.0\n",
    "    for i in range(n):\n",
    "        if i < n - 1:\n",
    "            coords[i] = product * np.cos(angles[i])\n",
    "            product *= np.sin(angles[i])\n",
    "        else:\n",
    "            coords[i] = product\n",
    "    return coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9029a56b-eb33-46e0-9630-80c1e93130a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polar Angles (3D): [0.95531662 0.78539816]\n",
      "Reconstructed Cartesian (3D): [0.57735027 0.57735027 0.57735027]\n"
     ]
    }
   ],
   "source": [
    "# Cartesian to Polar\n",
    "cartesian_coords = [1, 1, 1]\n",
    "polar_angles = cartesian_to_polar_nd(cartesian_coords)\n",
    "print(\"Polar Angles (3D):\", polar_angles)\n",
    "\n",
    "# Polar to Cartesian\n",
    "reconstructed_cartesian = polar_to_cartesian_nd(polar_angles)\n",
    "print(\"Reconstructed Cartesian (3D):\", reconstructed_cartesian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "789468d3-60ec-4b82-ac7c-1d40629dd861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polar Angles (4D): [1.04719755 0.95531662 0.78539816]\n",
      "Reconstructed Cartesian (4D): [0.5 0.5 0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "# Cartesian to Polar\n",
    "cartesian_coords = [1, 1, 1, 1]\n",
    "polar_angles = cartesian_to_polar_nd(cartesian_coords)\n",
    "print(\"Polar Angles (4D):\", polar_angles)\n",
    "\n",
    "# Polar to Cartesian\n",
    "reconstructed_cartesian = polar_to_cartesian_nd(polar_angles)\n",
    "print(\"Reconstructed Cartesian (4D):\", reconstructed_cartesian)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ce8c84-1378-4d50-9b59-47d6bf964ed1",
   "metadata": {},
   "source": [
    "To compute the Jacobian of the inverse mapping from the ball \\(\\mathbb{B}^K(1)\\) to the polytope \\(\\mathcal{F}^\\ddagger\\), let’s carefully outline the steps. Here's how the problem breaks down:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Understanding the Mapping**\n",
    "\n",
    "The given mapping can be expressed as:\n",
    "\n",
    "1. **Forward Mapping (Polytope \\(\\to\\) Ball):**\n",
    "\n",
    "   \\[\n",
    "   \\vec{v}^\\ddagger \\to \\vec{v}^\\mathbb{S} = [r, \\vec{p}]^T\n",
    "   \\]\n",
    "\n",
    "   Where:\n",
    "   - \\(r = \\frac{d}{\\alpha^{\\max}}\\) with \\(d = \\|\\vec{v}^\\ddagger\\|_2\\), and \\(\\alpha^{\\max} = \\min(\\vec{\\alpha} \\mid \\vec{\\alpha} \\geq 0)\\).\n",
    "   - \\(\\vec{p} = \\text{polar}(\\vec{c}) = \\text{polar}(\\frac{\\vec{v}^\\ddagger}{d})\\) gives the spherical coordinates of the direction vector.\n",
    "\n",
    "2. **Inverse Mapping (Ball \\(\\to\\) Polytope):**\n",
    "\n",
    "   \\[\n",
    "   \\vec{v}^\\mathbb{S} = [r, \\vec{p}]^T \\to \\vec{v}^\\ddagger\n",
    "   \\]\n",
    "\n",
    "   Where:\n",
    "   - \\(\\vec{c}\\) is reconstructed from the polar coordinates \\(\\vec{p}\\): \\(\\vec{c} = \\text{cartesian}(\\vec{p})\\).\n",
    "   - \\(d = r \\cdot \\alpha^{\\max}\\), where \\(\\alpha^{\\max}\\) is determined by solving \\(\\alpha^{\\max} = \\min(\\vec{\\alpha} \\mid \\vec{\\alpha} \\geq 0)\\), with:\n",
    "     \\[\n",
    "     \\vec{\\alpha} = \\vec{b}^\\ddagger \\oslash (\\pmb{A}^\\ddagger \\cdot \\vec{c}).\n",
    "     \\]\n",
    "   - \\(\\vec{v}^\\ddagger = d \\cdot \\vec{c}\\).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Inverse Mapping Function**\n",
    "\n",
    "The inverse mapping is explicitly given as:\n",
    "\\[\n",
    "\\vec{v}^\\ddagger = r \\cdot \\alpha^{\\max} \\cdot \\vec{c},\n",
    "\\]\n",
    "where:\n",
    "1. \\(\\vec{c}\\) depends on the polar coordinates \\(\\vec{p}\\).\n",
    "2. \\(r\\) is the radial distance.\n",
    "3. \\(\\alpha^{\\max}\\) depends on \\(\\vec{c}\\) and is defined as:\n",
    "   \\[\n",
    "   \\alpha^{\\max} = \\min(\\vec{\\alpha} \\mid \\vec{\\alpha} \\geq 0), \\quad \\vec{\\alpha} = \\vec{b}^\\ddagger \\oslash (\\pmb{A}^\\ddagger \\cdot \\vec{c}).\n",
    "   \\]\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Jacobian of the Inverse Mapping**\n",
    "\n",
    "To compute the Jacobian \\(J_{\\text{inv}}\\), we need to differentiate the inverse mapping \\(\\vec{v}^\\ddagger = f_{\\text{inv}}(r, \\vec{p})\\) with respect to \\([r, \\vec{p}]^T\\).\n",
    "\n",
    "#### Expression for \\(\\vec{v}^\\ddagger\\):\n",
    "\\[\n",
    "\\vec{v}^\\ddagger = r \\cdot \\alpha^{\\max} \\cdot \\vec{c}.\n",
    "\\]\n",
    "\n",
    "The Jacobian will have contributions from the derivatives of:\n",
    "1. \\(\\vec{c}\\) (which depends on \\(\\vec{p}\\)),\n",
    "2. \\(\\alpha^{\\max}\\) (which depends on \\(\\vec{c}\\) and indirectly on \\(\\vec{p}\\)).\n",
    "\n",
    "#### Components of the Jacobian:\n",
    "\n",
    "1. **Derivative with respect to \\(r\\):**\n",
    "   \\[\n",
    "   \\frac{\\partial \\vec{v}^\\ddagger}{\\partial r} = \\alpha^{\\max} \\cdot \\vec{c}.\n",
    "   \\]\n",
    "\n",
    "2. **Derivative with respect to \\(\\vec{p}\\):**\n",
    "   Using the product rule:\n",
    "   \\[\n",
    "   \\frac{\\partial \\vec{v}^\\ddagger}{\\partial \\vec{p}} = r \\cdot \\frac{\\partial (\\alpha^{\\max})}{\\partial \\vec{p}} \\cdot \\vec{c} + r \\cdot \\alpha^{\\max} \\cdot \\frac{\\partial \\vec{c}}{\\partial \\vec{p}}.\n",
    "   \\]\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Breaking Down Derivatives**\n",
    "\n",
    "#### \\(\\frac{\\partial \\vec{c}}{\\partial \\vec{p}}\\):\n",
    "This is the Jacobian of the transformation from polar to Cartesian coordinates. In \\(K\\)-dimensions:\n",
    "\\[\n",
    "\\vec{c} = \\text{cartesian}(\\vec{p}),\n",
    "\\]\n",
    "and its derivatives are standard for polar-to-Cartesian transformations.\n",
    "\n",
    "#### \\(\\frac{\\partial \\alpha^{\\max}}{\\partial \\vec{p}}\\):\n",
    "Since:\n",
    "\\[\n",
    "\\alpha^{\\max} = \\min(\\vec{\\alpha} \\mid \\vec{\\alpha} \\geq 0),\n",
    "\\]\n",
    "where:\n",
    "\\[\n",
    "\\vec{\\alpha} = \\vec{b}^\\ddagger \\oslash (\\pmb{A}^\\ddagger \\cdot \\vec{c}),\n",
    "\\]\n",
    "the gradient of \\(\\alpha^{\\max}\\) depends on the closest constraint. Let \\(\\vec{\\alpha}_i\\) be the active constraint:\n",
    "\\[\n",
    "\\frac{\\partial \\alpha^{\\max}}{\\partial \\vec{c}} = -\\frac{\\vec{b}^\\ddagger_i}{(\\pmb{A}^\\ddagger \\cdot \\vec{c})_i^2} \\cdot \\pmb{A}^\\ddagger_i.\n",
    "\\]\n",
    "\n",
    "Using the chain rule:\n",
    "\\[\n",
    "\\frac{\\partial \\alpha^{\\max}}{\\partial \\vec{p}} = \\frac{\\partial \\alpha^{\\max}}{\\partial \\vec{c}} \\cdot \\frac{\\partial \\vec{c}}{\\partial \\vec{p}}.\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Final Jacobian**\n",
    "\n",
    "The full Jacobian is:\n",
    "\\[\n",
    "J_{\\text{inv}} = \\begin{bmatrix}\n",
    "\\frac{\\partial \\vec{v}^\\ddagger}{\\partial r} & \\frac{\\partial \\vec{v}^\\ddagger}{\\partial \\vec{p}}\n",
    "\\end{bmatrix},\n",
    "\\]\n",
    "where:\n",
    "\\[\n",
    "\\frac{\\partial \\vec{v}^\\ddagger}{\\partial r} = \\alpha^{\\max} \\cdot \\vec{c},\n",
    "\\]\n",
    "and:\n",
    "\\[\n",
    "\\frac{\\partial \\vec{v}^\\ddagger}{\\partial \\vec{p}} = r \\cdot \\frac{\\partial (\\alpha^{\\max})}{\\partial \\vec{p}} \\cdot \\vec{c} + r \\cdot \\alpha^{\\max} \\cdot \\frac{\\partial \\vec{c}}{\\partial \\vec{p}}.\n",
    "\\]\n",
    "\n",
    "This expression accounts for the dependencies on both \\(r\\) and \\(\\vec{p}\\). Let me know if you want explicit forms for \\(\\frac{\\partial \\vec{c}}{\\partial \\vec{p}}\\) in a specific dimension!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e92977-006b-4d25-b9f4-2411ad8b4608",
   "metadata": {},
   "source": [
    "Let’s derive the expressions for the derivatives of \\(\\vec{v}^\\ddagger = r \\cdot \\alpha^{\\max} \\cdot \\vec{c}\\) with respect to \\(r\\) and the polar coordinates \\(\\vec{p} = [\\varphi_1, \\dots, \\varphi_{K-2}, \\theta]\\).\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Expression for \\(\\vec{v}^\\ddagger\\):\n",
    "The inverse mapping is:\n",
    "\\[\n",
    "\\vec{v}^\\ddagger = r \\cdot \\alpha^{\\max} \\cdot \\vec{c},\n",
    "\\]\n",
    "where:\n",
    "- \\(r \\in [0, 1]\\) is the radial distance,\n",
    "- \\(\\alpha^{\\max} = \\min\\left(\\vec{\\alpha} \\mid \\vec{\\alpha} \\geq 0\\right)\\),\n",
    "- \\(\\vec{\\alpha} = \\vec{b}^\\ddagger \\oslash (\\pmb{A}^\\ddagger \\cdot \\vec{c})\\),\n",
    "- \\(\\vec{c}\\) is the Cartesian representation of the polar coordinates \\(\\vec{p}\\):\n",
    "  \\[\n",
    "  \\vec{c} = \\text{cartesian}(\\vec{p}).\n",
    "  \\]\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Derivative with Respect to \\(r\\):\n",
    "To compute \\(\\frac{\\partial \\vec{v}^\\ddagger}{\\partial r}\\), treat \\(r\\) as a scalar multiplier:\n",
    "\\[\n",
    "\\frac{\\partial \\vec{v}^\\ddagger}{\\partial r} = \\alpha^{\\max} \\cdot \\vec{c}.\n",
    "\\]\n",
    "\n",
    "- Here, \\(\\alpha^{\\max}\\) and \\(\\vec{c}\\) are functions of \\(\\vec{p}\\), but they are independent of \\(r\\).\n",
    "- Therefore, the derivative is straightforward.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Derivative with Respect to Polar Coordinates (\\(\\vec{p}\\)):\n",
    "The derivative with respect to polar coordinates \\(\\vec{p}\\) is more complex because \\(\\vec{v}^\\ddagger\\) depends on \\(\\vec{p}\\) both through \\(\\vec{c}\\) and \\(\\alpha^{\\max}\\). Using the product rule:\n",
    "\\[\n",
    "\\frac{\\partial \\vec{v}^\\ddagger}{\\partial \\vec{p}} = r \\cdot \\frac{\\partial (\\alpha^{\\max})}{\\partial \\vec{p}} \\cdot \\vec{c} + r \\cdot \\alpha^{\\max} \\cdot \\frac{\\partial \\vec{c}}{\\partial \\vec{p}}.\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "#### 3.1. Derivative of \\(\\vec{c}\\) with Respect to \\(\\vec{p}\\):\n",
    "Recall that \\(\\vec{c}\\) is computed from polar coordinates:\n",
    "\\[\n",
    "\\vec{c} = \\begin{bmatrix}\n",
    "\\cos(\\varphi_1) \\\\\n",
    "\\sin(\\varphi_1) \\cos(\\varphi_2) \\\\\n",
    "\\sin(\\varphi_1) \\sin(\\varphi_2) \\cos(\\varphi_3) \\\\\n",
    "\\vdots \\\\\n",
    "\\prod_{i=1}^{K-2} \\sin(\\varphi_i) \\cos(\\theta) \\\\\n",
    "\\prod_{i=1}^{K-2} \\sin(\\varphi_i) \\sin(\\theta)\n",
    "\\end{bmatrix}.\n",
    "\\]\n",
    "\n",
    "The derivative of \\(\\vec{c}\\) with respect to the polar coordinates \\(\\vec{p} = [\\varphi_1, \\dots, \\varphi_{K-2}, \\theta]\\) can be computed component-wise. For example:\n",
    "- For \\(\\frac{\\partial \\vec{c}}{\\partial \\varphi_1}\\):\n",
    "  \\[\n",
    "  \\frac{\\partial c_1}{\\partial \\varphi_1} = -\\sin(\\varphi_1), \\quad \\frac{\\partial c_2}{\\partial \\varphi_1} = \\cos(\\varphi_1) \\cos(\\varphi_2), \\quad \\text{etc.}\n",
    "  \\]\n",
    "- For \\(\\frac{\\partial \\vec{c}}{\\partial \\theta}\\), only the last two components depend on \\(\\theta\\):\n",
    "  \\[\n",
    "  \\frac{\\partial c_{K-1}}{\\partial \\theta} = -\\prod_{i=1}^{K-2} \\sin(\\varphi_i) \\sin(\\theta), \\quad \\frac{\\partial c_K}{\\partial \\theta} = \\prod_{i=1}^{K-2} \\sin(\\varphi_i) \\cos(\\theta).\n",
    "  \\]\n",
    "\n",
    "The full derivative \\(\\frac{\\partial \\vec{c}}{\\partial \\vec{p}}\\) is the Jacobian matrix of the polar-to-Cartesian transformation.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3.2. Derivative of \\(\\alpha^{\\max}\\) with Respect to \\(\\vec{p}\\):\n",
    "\\(\\alpha^{\\max}\\) depends on \\(\\vec{p}\\) through \\(\\vec{c}\\). The derivative is:\n",
    "\\[\n",
    "\\frac{\\partial \\alpha^{\\max}}{\\partial \\vec{p}} = \\frac{\\partial \\alpha^{\\max}}{\\partial \\vec{c}} \\cdot \\frac{\\partial \\vec{c}}{\\partial \\vec{p}}.\n",
    "\\]\n",
    "\n",
    "From the definition of \\(\\alpha^{\\max}\\):\n",
    "\\[\n",
    "\\alpha^{\\max} = \\min\\left(\\vec{\\alpha} \\mid \\vec{\\alpha} \\geq 0\\right), \\quad \\vec{\\alpha} = \\vec{b}^\\ddagger \\oslash (\\pmb{A}^\\ddagger \\cdot \\vec{c}),\n",
    "\\]\n",
    "the gradient of \\(\\alpha^{\\max}\\) with respect to \\(\\vec{c}\\) is:\n",
    "\\[\n",
    "\\frac{\\partial \\alpha^{\\max}}{\\partial \\vec{c}} = -\\frac{\\vec{b}^\\ddagger_i}{(\\pmb{A}^\\ddagger \\cdot \\vec{c})_i^2} \\cdot \\pmb{A}^\\ddagger_i,\n",
    "\\]\n",
    "where \\(i\\) corresponds to the active constraint (i.e., the constraint achieving \\(\\alpha^{\\max}\\)).\n",
    "\n",
    "Thus:\n",
    "\\[\n",
    "\\frac{\\partial \\alpha^{\\max}}{\\partial \\vec{p}} = -\\frac{\\vec{b}^\\ddagger_i}{(\\pmb{A}^\\ddagger \\cdot \\vec{c})_i^2} \\cdot \\pmb{A}^\\ddagger_i \\cdot \\frac{\\partial \\vec{c}}{\\partial \\vec{p}}.\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Final Expressions\n",
    "\n",
    "1. **Derivative with respect to \\(r\\):**\n",
    "   \\[\n",
    "   \\frac{\\partial \\vec{v}^\\ddagger}{\\partial r} = \\alpha^{\\max} \\cdot \\vec{c}.\n",
    "   \\]\n",
    "\n",
    "2. **Derivative with respect to \\(\\vec{p}\\):**\n",
    "   \\[\n",
    "   \\frac{\\partial \\vec{v}^\\ddagger}{\\partial \\vec{p}} = r \\cdot \\left( -\\frac{\\vec{b}^\\ddagger_i}{(\\pmb{A}^\\ddagger \\cdot \\vec{c})_i^2} \\cdot \\pmb{A}^\\ddagger_i \\cdot \\frac{\\partial \\vec{c}}{\\partial \\vec{p}} \\right) \\cdot \\vec{c} + r \\cdot \\alpha^{\\max} \\cdot \\frac{\\partial \\vec{c}}{\\partial \\vec{p}}.\n",
    "   \\]\n",
    "\n",
    "These expressions combine the effects of both \\(\\alpha^{\\max}\\) and \\(\\vec{c}\\) on \\(\\vec{v}^\\ddagger\\)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265a42d-31ac-4e77-9833-aa27f7259b4f",
   "metadata": {},
   "source": [
    "Certainly! Let’s break down the computation for a **single entry** in the Jacobian of \\(\\vec{v}^\\ddagger = r \\cdot \\alpha^{\\max} \\cdot \\vec{c}\\) with respect to one polar coordinate, say \\(\\varphi_j\\).\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Expression for \\(\\vec{v}^\\ddagger\\):\n",
    "The inverse mapping is:\n",
    "\\[\n",
    "\\vec{v}^\\ddagger = r \\cdot \\alpha^{\\max} \\cdot \\vec{c},\n",
    "\\]\n",
    "where:\n",
    "- \\(r\\) is the radial distance,\n",
    "- \\(\\alpha^{\\max}\\) is the distance to the nearest constraint,\n",
    "- \\(\\vec{c}\\) is the Cartesian representation of the polar coordinates \\(\\vec{p}\\).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Derivative of \\(\\vec{v}^\\ddagger\\) with respect to \\(\\varphi_j\\):\n",
    "Using the product rule:\n",
    "\\[\n",
    "\\frac{\\partial \\vec{v}^\\ddagger}{\\partial \\varphi_j} = r \\cdot \\frac{\\partial (\\alpha^{\\max})}{\\partial \\varphi_j} \\cdot \\vec{c} + r \\cdot \\alpha^{\\max} \\cdot \\frac{\\partial \\vec{c}}{\\partial \\varphi_j}.\n",
    "\\]\n",
    "\n",
    "#### Step 1: \\(\\frac{\\partial \\vec{c}}{\\partial \\varphi_j}\\)\n",
    "The Cartesian coordinates \\(\\vec{c} = [c_1, c_2, \\dots, c_K]\\) depend on the polar angles \\([\\varphi_1, \\dots, \\varphi_{K-2}, \\theta]\\). Each component \\(c_k\\) can be written as:\n",
    "\\[\n",
    "c_k = \\prod_{i=1}^{k-1} \\sin(\\varphi_i) \\cdot \n",
    "\\begin{cases} \n",
    "\\cos(\\varphi_k) & \\text{if } k < K, \\\\\n",
    "\\cos(\\theta) & \\text{if } k = K-1, \\\\\n",
    "\\sin(\\theta) & \\text{if } k = K.\n",
    "\\end{cases}\n",
    "\\]\n",
    "\n",
    "The derivative of \\(c_k\\) with respect to \\(\\varphi_j\\) depends on \\(j\\):\n",
    "- If \\(j < k\\), \\(c_k\\) includes \\(\\sin(\\varphi_j)\\), so:\n",
    "  \\[\n",
    "  \\frac{\\partial c_k}{\\partial \\varphi_j} = \\prod_{i=1}^{j-1} \\sin(\\varphi_i) \\cdot \\cos(\\varphi_j) \\cdot \\prod_{i=j+1}^{k-1} \\sin(\\varphi_i) \\cdot (\\text{rest of } c_k).\n",
    "  \\]\n",
    "- If \\(j = k\\), \\(c_k = \\cos(\\varphi_k)\\), so:\n",
    "  \\[\n",
    "  \\frac{\\partial c_k}{\\partial \\varphi_j} = -\\prod_{i=1}^{j-1} \\sin(\\varphi_i) \\cdot \\sin(\\varphi_j).\n",
    "  \\]\n",
    "- If \\(j > k\\), \\(c_k\\) is independent of \\(\\varphi_j\\), so:\n",
    "  \\[\n",
    "  \\frac{\\partial c_k}{\\partial \\varphi_j} = 0.\n",
    "  \\]\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 2: \\(\\frac{\\partial (\\alpha^{\\max})}{\\partial \\varphi_j}\\)\n",
    "The distance \\(\\alpha^{\\max}\\) depends on \\(\\vec{c}\\):\n",
    "\\[\n",
    "\\alpha^{\\max} = \\min\\left(\\vec{\\alpha} \\mid \\vec{\\alpha} \\geq 0\\right), \\quad \\vec{\\alpha} = \\vec{b}^\\ddagger \\oslash (\\pmb{A}^\\ddagger \\cdot \\vec{c}).\n",
    "\\]\n",
    "\n",
    "The derivative of \\(\\alpha^{\\max}\\) with respect to \\(\\varphi_j\\) is:\n",
    "\\[\n",
    "\\frac{\\partial \\alpha^{\\max}}{\\partial \\varphi_j} = -\\frac{b^\\ddagger_i}{\\left(\\pmb{A}^\\ddagger \\cdot \\vec{c}\\right)_i^2} \\cdot \\pmb{A}^\\ddagger_{i, :} \\cdot \\frac{\\partial \\vec{c}}{\\partial \\varphi_j},\n",
    "\\]\n",
    "where \\(i\\) is the index of the active constraint (the one that achieves \\(\\alpha^{\\max}\\)).\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 3: Putting it Together\n",
    "Combining both terms:\n",
    "\\[\n",
    "\\frac{\\partial v^\\ddagger_k}{\\partial \\varphi_j} = r \\cdot \\left[ -\\frac{b^\\ddagger_i}{\\left(\\pmb{A}^\\ddagger \\cdot \\vec{c}\\right)_i^2} \\cdot A^\\ddagger_{i, k} \\cdot \\frac{\\partial c_k}{\\partial \\varphi_j} \\right] + r \\cdot \\alpha^{\\max} \\cdot \\frac{\\partial c_k}{\\partial \\varphi_j}.\n",
    "\\]\n",
    "\n",
    "Here:\n",
    "1. \\(\\frac{\\partial c_k}{\\partial \\varphi_j}\\) depends on whether \\(j < k\\), \\(j = k\\), or \\(j > k\\), as shown above.\n",
    "2. The first term includes the dependence of \\(\\alpha^{\\max}\\) on \\(\\varphi_j\\) and involves the constraint matrix \\(\\pmb{A}^\\ddagger\\).\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Single Entry Example\n",
    "If \\(k = 3\\) and \\(j = 2\\), the derivative is:\n",
    "\\[\n",
    "\\frac{\\partial v^\\ddagger_3}{\\partial \\varphi_2} = r \\cdot \\left[ -\\frac{b^\\ddagger_i}{\\left(\\pmb{A}^\\ddagger \\cdot \\vec{c}\\right)_i^2} \\cdot A^\\ddagger_{i, 3} \\cdot \\frac{\\partial c_3}{\\partial \\varphi_2} \\right] + r \\cdot \\alpha^{\\max} \\cdot \\frac{\\partial c_3}{\\partial \\varphi_2}.\n",
    "\\]\n",
    "\n",
    "Here:\n",
    "- \\(\\frac{\\partial c_3}{\\partial \\varphi_2}\\) is determined from the Cartesian-to-polar relationship.\n",
    "\n",
    "If you'd like, I can further simplify it for specific values or provide Python code! Let me know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4caef5-b295-4484-809d-5b9787795f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67483b1e-0422-4164-abe5-124244be83a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_set:\n",
      "  i=0 => [0. 0.]\n",
      "  i=1 => [ 1.624 -0.612]\n",
      "  i=2 => [-0.528 -1.073]\n",
      "  i=3 => [ 0.865 -2.302]\n",
      "\n",
      "Barker Transition Matrix T (force_jump=False):\n",
      "[[0.    0.248 0.727 0.025]\n",
      " [0.477 0.    0.477 0.046]\n",
      " [0.727 0.248 0.    0.025]\n",
      " [0.34  0.319 0.34  0.   ]]\n",
      "\n",
      "Row sums (should be 1): [1. 1. 1. 1.]\n",
      "\n",
      "Sampled next index from row 0 => i_next=2, x_next=[-0.528 -1.073]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tjelmeland_barker_transition_matrix(\n",
    "    x_set,\n",
    "    log_pi,\n",
    "    log_q,\n",
    "    force_jump=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Construct Tjelmeland's multi-proposal Barker transition kernel \n",
    "    for x_set = [x_0, x_1, ..., x_K],\n",
    "    allowing (but not guaranteeing) a nonzero self-transition if force_jump=False.\n",
    "\n",
    "    Barker's pairwise function:\n",
    "        phi(u,v) = u / (u + v)\n",
    "    ensures detailed balance if each row is normalized \n",
    "    so that T[i,j] = phi(w[i,j], w[j,i]) / sum_k phi(w[i,k], w[k,i]) for k != i.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_set : list of np.ndarray\n",
    "        (K+1) states: x_set[0] is 'current' state, x_set[1..K] are proposals.\n",
    "    log_pi : callable\n",
    "        log_pi(x) -> float, log of target density at x (up to a constant).\n",
    "    log_q : callable\n",
    "        log_q(x_from, x_to) -> float, log of proposal PDF q(x_from-> x_to).\n",
    "    force_jump : bool\n",
    "        If True, set T[i,i] = 0 explicitly. \n",
    "        If False, set T[i,i] = leftover so that each row sums to 1 \n",
    "        (but often leftover is zero anyway, given how Barker’s rule sums up).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    T : (K+1) x (K+1) np.ndarray\n",
    "        Row-stochastic matrix. T[i,j] = probability of moving from x_i to x_j.\n",
    "    \"\"\"\n",
    "    def barker_phi(u, v):\n",
    "        # phi(u,v) = u/(u+v), with safe handling for edge cases\n",
    "        if u <= 0 and v <= 0:\n",
    "            return 0.0\n",
    "        return u / (u + v)\n",
    "\n",
    "    n = len(x_set)\n",
    "    T = np.zeros((n, n), dtype=float)\n",
    "\n",
    "    # 1) Build the log-weights w[i->j] = log [ pi(x_j)*q(x_j-> x_i) ]\n",
    "    log_w = np.full((n, n), -np.inf)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                val = log_pi(x_set[j]) + log_q(x_set[j], x_set[i])\n",
    "                log_w[i,j] = val\n",
    "            else:\n",
    "                log_w[i,j] = -np.inf\n",
    "\n",
    "    # Exponentiate rows stably\n",
    "    w = np.zeros((n, n), dtype=float)\n",
    "    for i in range(n):\n",
    "        row_vals = log_w[i, :]\n",
    "        max_val = np.max(row_vals)\n",
    "        if np.isfinite(max_val):\n",
    "            row_exp = np.exp(row_vals - max_val)\n",
    "            w[i,:] = row_exp\n",
    "        # else remains zeros\n",
    "\n",
    "    # 2) Compute row i, T[i,j] = phi(w[i,j], w[j,i]) / sum_{k != i} phi(...).\n",
    "    for i in range(n):\n",
    "        phi_vals = np.zeros(n, dtype=float)\n",
    "        for k in range(n):\n",
    "            if k != i:\n",
    "                phi_vals[k] = barker_phi(w[i,k], w[k,i])\n",
    "\n",
    "        denom = np.sum(phi_vals)\n",
    "        if denom > 0:\n",
    "            # Off-diagonal probabilities\n",
    "            for j in range(n):\n",
    "                if j != i:\n",
    "                    T[i,j] = phi_vals[j] / denom\n",
    "            if force_jump:\n",
    "                # Force zero self-transition\n",
    "                T[i,i] = 0.0\n",
    "            else:\n",
    "                # Let leftover = 1 - sum_{j!=i} T[i,j].\n",
    "                # Usually sum_{j!=i} T[i,j] = 1.0 => leftover=0\n",
    "                leftover = 1.0 - np.sum(T[i, :])\n",
    "                # If leftover < 0, that means sum_{j!=i} T[i,j] > 1 => numerical or Barker’s rule\n",
    "                # We'll just clamp to 0 to keep row-stochastic\n",
    "                T[i,i] = max(0.0, leftover)\n",
    "                # Then re-normalize the row so it sums to 1\n",
    "                row_sum = np.sum(T[i,:])\n",
    "                if row_sum > 0:\n",
    "                    T[i,:] /= row_sum\n",
    "                else:\n",
    "                    # degenerate: everything is 0 => stay put\n",
    "                    T[i,i] = 1.0\n",
    "        else:\n",
    "            # If no valid moves => remain with prob 1\n",
    "            T[i,i] = 1.0\n",
    "\n",
    "    return T\n",
    "\n",
    "def sample_from_transition(i_current, T):\n",
    "    \"\"\"Sample next index from row i_current of matrix T.\"\"\"\n",
    "    p = T[i_current, :]\n",
    "    i_next = np.random.choice(len(p), p=p)\n",
    "    return i_next\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# DEMO\n",
    "if __name__ == \"__main__\":\n",
    "    # Example target: 2D standard Gaussian\n",
    "    def log_pi_gaussian(z):\n",
    "        return -0.5 * np.sum(z**2)  # ignoring additive constants\n",
    "\n",
    "    # Isotropic Gaussian proposal\n",
    "    sigma = 1.0\n",
    "    def sample_q(x):\n",
    "        return x + sigma * np.random.randn(*x.shape)\n",
    "    def log_q(x_from, x_to):\n",
    "        diff = x_to - x_from\n",
    "        return -0.5 * np.sum(diff**2) / (sigma**2)\n",
    "\n",
    "    np.random.seed(1)\n",
    "    x0 = np.array([0.0, 0.0])\n",
    "\n",
    "    K = 3\n",
    "    # Suppose we propose K states from x0\n",
    "    proposals = [sample_q(x0) for _ in range(K)]\n",
    "    x_set = [x0] + proposals\n",
    "\n",
    "    # Build T with force_jump=False\n",
    "    T = tjelmeland_barker_transition_matrix(\n",
    "        x_set, log_pi_gaussian, log_q, force_jump=False\n",
    "    )\n",
    "\n",
    "    print(\"x_set:\")\n",
    "    for i, s in enumerate(x_set):\n",
    "        print(f\"  i={i} => {s}\")\n",
    "\n",
    "    print(\"\\nBarker Transition Matrix T (force_jump=False):\")\n",
    "    np.set_printoptions(precision=3, suppress=True)\n",
    "    print(T)\n",
    "\n",
    "    row_sums = T.sum(axis=1)\n",
    "    print(\"\\nRow sums (should be 1):\", row_sums)\n",
    "\n",
    "    # Sample from row 0\n",
    "    i_next = sample_from_transition(0, T)\n",
    "    print(f\"\\nSampled next index from row 0 => i_next={i_next}, x_next={x_set[i_next]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7faefe7d-cb2f-4df9-aed6-9513055acc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States (K+1):\n",
      " i=0 => [0. 0.]\n",
      " i=1 => [-0.066 -0.209]\n",
      " i=2 => [ 1.347 -0.607]\n",
      " i=3 => [-0.174  0.424]\n",
      "\n",
      "Transition matrix T (rows sum to 1):\n",
      "[[0.348 0.331 0.039 0.282]\n",
      " [0.349 0.349 0.041 0.262]\n",
      " [0.287 0.284 0.287 0.142]\n",
      " [0.339 0.299 0.023 0.339]]\n",
      "\n",
      "From i_current=0 (i.e., [0. 0.]), we sample i_next=1\n",
      "   => next state in x_set is [-0.066 -0.209]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tjelmeland_peskun_transition_matrix(x_set, log_pi, log_q):\n",
    "    \"\"\"\n",
    "    Construct Tjelmeland's Peskun transition matrix for states in x_set = [x_0, x_1, ..., x_K].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_set : list of np.ndarray\n",
    "        List of (K+1) states: x_set[0] is the 'current' state, x_set[1..K] are proposals.\n",
    "    log_pi : callable\n",
    "        log_pi(x) -> float, returns log of target density at x.\n",
    "    log_q : callable\n",
    "        log_q(x_from, x_to) -> float, returns log of proposal PDF q(x_from-> x_to).\n",
    "    Returns\n",
    "    -------\n",
    "    T : np.ndarray, shape (K+1, K+1)\n",
    "        Row-stochastic transition matrix satisfying detailed balance w.r.t. pi.\n",
    "        T[i,j] = probability of moving from state i to state j.\n",
    "    \"\"\"\n",
    "    n = len(x_set)  # K+1 states\n",
    "    T = np.zeros((n, n), dtype=float)\n",
    "\n",
    "    # Compute unnormalized weights w_{i->j}\n",
    "    # w_{i->j} = pi(x_j) * q(x_j -> x_i), for i != j\n",
    "    # We'll work in the log domain for numerical stability:\n",
    "    log_w = np.full((n, n), -np.inf)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                # log_w[i,j] = log_pi(x_j) + log_q(x_j, x_i)\n",
    "                log_w[i,j] = log_pi(x_set[j]) + log_q(x_set[j], x_set[i])\n",
    "            else:\n",
    "                # log_w[i,j] = -np.inf  # i == j => no self-transition weight\n",
    "                log_w[i,j] = log_pi(x_set[j]) + log_q(x_set[j], x_set[i])  # i == j => no self-transition weight\n",
    "\n",
    "    # Now, for each row i, we normalize over j != i to get a probability distribution\n",
    "    for i in range(n):\n",
    "        # We want to exponentiate log_w[i,*] in a stable way\n",
    "        row_log_values = log_w[i, :]  # shape (n,)\n",
    "        max_val = np.max(row_log_values)\n",
    "        if np.isinf(max_val):\n",
    "            # Degenerate case, e.g. if all w_{i->j} = 0 for j != i\n",
    "            # We'll handle by letting T[i,i] = 1 or something\n",
    "            T[i,i] = 1.0\n",
    "        else:\n",
    "            # Exponentiate shifted values\n",
    "            row_exp = np.exp(row_log_values - max_val)  # shift for stability\n",
    "            row_sum = np.sum(row_exp)\n",
    "            if row_sum > 0:\n",
    "                T[i, :] = row_exp / row_sum\n",
    "            else:\n",
    "                # If row_sum=0, fallback\n",
    "                T[i, i] = 1.0\n",
    "\n",
    "    return T\n",
    "\n",
    "\n",
    "def sample_from_transition(i_current, T):\n",
    "    \"\"\"\n",
    "    Given a row-stochastic matrix T and a current row index i_current,\n",
    "    sample the next index from T[i_current, :].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    i_current : int\n",
    "        The current index in {0, 1, ..., K}.\n",
    "    T : np.ndarray\n",
    "        Transition matrix, shape (K+1, K+1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    i_next : int\n",
    "        The chosen next index, drawn with probabilities T[i_current, :].\n",
    "    \"\"\"\n",
    "    p = T[i_current, :]\n",
    "    i_next = np.random.choice(len(p), p=p)\n",
    "    return i_next\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# A DEMO USAGE\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: 2D standard Gaussian target distribution (log-scale)\n",
    "    def log_pi_gaussian(z):\n",
    "        return -0.5 * np.sum(z**2)  # ignoring normalizing constants\n",
    "\n",
    "    # Gaussian proposal: q(x->y) ~ N(x, sigma^2 I)\n",
    "    sigma = 1.0\n",
    "    def sample_q(x):\n",
    "        return x + sigma * np.random.randn(*x.shape)\n",
    "\n",
    "    def log_q(x_from, x_to):\n",
    "        diff = x_to - x_from\n",
    "        # log of N(0, sigma^2 I) ignoring constant dims => -|diff|^2/(2 sigma^2)\n",
    "        return -0.5 * np.sum(diff**2) / (sigma**2)\n",
    "\n",
    "    # We want to form x_set = [x_0, x_1, ..., x_K].\n",
    "    K = 3\n",
    "    x0 = np.array([0.0, 0.0])  # current state\n",
    "    proposals = [sample_q(x0) for _ in range(K)]\n",
    "    x_set = [x0] + proposals\n",
    "\n",
    "    # Build Tjelmeland's Peskun transition matrix\n",
    "    T = tjelmeland_peskun_transition_matrix(x_set, log_pi_gaussian, log_q)\n",
    "\n",
    "    # Current index is i=0 => corresponds to x0\n",
    "    i_current = 0\n",
    "    i_next = sample_from_transition(i_current, T)\n",
    "\n",
    "    print(\"States (K+1):\")\n",
    "    for i, xx in enumerate(x_set):\n",
    "        print(f\" i={i} => {xx}\")\n",
    "\n",
    "    print(\"\\nTransition matrix T (rows sum to 1):\")\n",
    "    np.set_printoptions(precision=3, suppress=True)\n",
    "    print(T)\n",
    "\n",
    "    print(f\"\\nFrom i_current=0 (i.e., {x0}), we sample i_next={i_next}\")\n",
    "    print(f\"   => next state in x_set is {x_set[i_next]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ccb0e-c585-4326-9f84-bef32991859d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
